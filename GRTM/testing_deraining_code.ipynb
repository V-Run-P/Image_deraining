{"cells":[{"cell_type":"markdown","metadata":{"id":"NzoyVDRdDsoR"},"source":["# Library\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"pmJfGpNjOIGn"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mdl/afs6372/anaconda3/envs/DiT/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n","  warnings.warn(\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torchvision.transforms.functional as TF\n","import torchvision\n","import torchvision.utils as vutils\n","\n","from torch.nn import init\n","import functools\n","from PIL import Image\n","import random\n","import os\n","import time\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","from pathlib import Path\n","from natsort import natsorted\n","from glob import glob\n","\n","from collections import OrderedDict\n","\n","from tqdm.notebook import tqdm\n","import math\n","\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","from skimage.metrics import structural_similarity as ssim \n","import pandas as pd\n","import numpy as np\n","import os\n","from os.path import exists\n","from pathlib import Path"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QSMchleKO8Zc"},"outputs":[],"source":["# Plot image\n","def show_img(img, title='No Title', normalize_range=False, figsize=15):\n","  plt.figure(figsize=(figsize, figsize))\n","  plt.imshow(img)\n","  plt.title(title)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XwbVoPMkCUKr"},"source":["# Model Definitions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Wg-OoS5f4DyZ"},"outputs":[],"source":["# Main network blocks\n","# Code modified from: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n","\n","# Basic Blocks\n","class Identity(nn.Module):\n","  def forward(self, x):\n","    return x\n","\n","def get_norm_layer(norm_type='instance'):\n","  \"\"\"Return a normalization layer\n","  Parameters:\n","      norm_type (str) -- the name of the normalization layer: batch | instance | none\n","  For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n","  For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n","  \"\"\"\n","  if norm_type == 'batch':\n","    norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n","  elif norm_type == 'instance':\n","    norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n","  elif norm_type == 'none':\n","    def norm_layer(x): return Identity()\n","  else:\n","    raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n","  return norm_layer\n","\n","class Conv2d(torch.nn.Module):\n","  '''\n","  2D convolution class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel\n","    stride : int\n","      stride of convolution\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","  '''\n","\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      stride=1,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect'):\n","    super(Conv2d, self).__init__()\n","    \n","    self.activation_func = activation_func\n","    conv_block = []\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(kernel_size // 2)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(kernel_size // 2)]\n","    elif padding_type == 'zero':\n","      p = kernel_size // 2\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","    conv_block += [\n","        nn.Conv2d(\n","            in_channels, \n","            out_channels, \n","            stride=stride,\n","            kernel_size=kernel_size, \n","            padding=p, \n","            bias=use_bias), \n","        norm_layer(out_channels)]\n","\n","    self.conv = nn.Sequential(*conv_block)\n","\n","  def forward(self, x):\n","    conv = self.conv(x)\n","\n","    if self.activation_func is not None:\n","      return self.activation_func(conv)\n","    else:\n","      return conv\n","\n","class DeformableConv2d(nn.Module):\n","  '''\n","  2D deformable convolution class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel\n","    stride : int\n","      stride of convolution\n","    padding : int\n","      padding\n","    use_bias : bool\n","      if set, then use bias\n","  '''\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      stride=1,\n","      padding=1,\n","      bias=False):\n","\n","    super(DeformableConv2d, self).__init__()\n","    \n","    self.stride = stride if type(stride) == tuple else (stride, stride)\n","    self.padding = padding\n","    \n","    self.offset_conv = nn.Conv2d(\n","        in_channels, \n","        2 * kernel_size * kernel_size,\n","        kernel_size=kernel_size, \n","        stride=stride,\n","        padding=self.padding, \n","        bias=True)\n","\n","    nn.init.constant_(self.offset_conv.weight, 0.)\n","    nn.init.constant_(self.offset_conv.bias, 0.)\n","    \n","    self.modulator_conv = nn.Conv2d(\n","        in_channels, \n","        1 * kernel_size * kernel_size,\n","        kernel_size=kernel_size, \n","        stride=stride,\n","        padding=self.padding, \n","        bias=True)\n","\n","    nn.init.constant_(self.modulator_conv.weight, 0.)\n","    nn.init.constant_(self.modulator_conv.bias, 0.)\n","    \n","    self.regular_conv = nn.Conv2d(\n","        in_channels=in_channels,\n","        out_channels=out_channels,\n","        kernel_size=kernel_size,\n","        stride=stride,\n","        padding=self.padding,\n","        bias=bias)\n","\n","  def forward(self, x):\n","    offset = self.offset_conv(x)\n","    modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","    \n","    x = torchvision.ops.deform_conv2d(\n","        input=x, \n","        offset=offset, \n","        weight=self.regular_conv.weight, \n","        bias=self.regular_conv.bias, \n","        padding=self.padding,\n","        mask=modulator,\n","        stride=self.stride)\n","    return x\n","\n","class UpConv2d(torch.nn.Module):\n","  '''\n","  Up-convolution (upsample + convolution) block class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel (k x k)\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","    interpolate_mode : str\n","      the mode for interpolation: bilinear | nearest\n","  '''\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect',\n","      interpolate_mode='bilinear'):\n","    \n","    super(UpConv2d, self).__init__()\n","    self.interpolate_mode = interpolate_mode\n","\n","    self.conv = Conv2d(\n","        in_channels,\n","        out_channels,\n","        kernel_size=kernel_size,\n","        stride=1,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        use_bias=use_bias,\n","        padding_type=padding_type)\n","\n","  def forward(self, x):\n","    n_height, n_width = x.shape[2:4]\n","    shape = (int(2 * n_height), int(2 * n_width))\n","    upsample = torch.nn.functional.interpolate(\n","        x, size=shape, mode=self.interpolate_mode, align_corners=True)\n","    conv = self.conv(upsample)\n","    return conv\n","\n","class DeformableResnetBlock(nn.Module):\n","  \"\"\"Define a Resnet block with deformable convolutions\"\"\"\n","\n","  def __init__(\n","      self, dim, padding_type, \n","      norm_layer, use_dropout, \n","      use_bias, activation_func):\n","    \"\"\"Initialize the deformable Resnet block\n","    A defromable resnet block is a conv block with skip connections\n","    \"\"\"\n","    super(DeformableResnetBlock, self).__init__()\n","    self.conv_block = self.build_conv_block(\n","        dim, padding_type, \n","        norm_layer, use_dropout, \n","        use_bias, activation_func)\n","\n","  def build_conv_block(\n","      self, dim, padding_type, \n","      norm_layer, use_dropout, \n","      use_bias, activation_func):\n","    \"\"\"Construct a convolutional block.\n","    Parameters:\n","        dim (int) -- the number of channels in the conv layer.\n","        padding_type (str) -- the name of padding layer: reflect | replicate | zero\n","        norm_layer -- normalization layer\n","        use_dropout (bool) -- if use dropout layers.\n","        use_bias (bool) -- if the conv layer uses bias or not\n","        activation_func (func) -- activation type\n","    Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer)\n","    \"\"\"\n","    conv_block = []\n","\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(1)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(1)]\n","    elif padding_type == 'zero':\n","      p = 1\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","    conv_block += [\n","        DeformableConv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), \n","        norm_layer(dim), \n","        activation_func]\n","    if use_dropout:\n","      conv_block += [nn.Dropout(0.5)]\n","\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(1)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(1)]\n","    elif padding_type == 'zero':\n","      p = 1\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","    conv_block += [DeformableConv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n","\n","    return nn.Sequential(*conv_block)\n","\n","  def forward(self, x):\n","    \"\"\"Forward function (with skip connections)\"\"\"\n","    out = x + self.conv_block(x)    # add skip connections\n","    return out\n","\n","class DecoderBlock(torch.nn.Module):\n","  '''\n","  Decoder block with skip connections\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    skip_channels : int\n","      number of skip connection channels\n","    out_channels : int\n","      number of output channels\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","    upsample_mode : str\n","      the mode for interpolation: transpose | bilinear | nearest\n","  '''\n","\n","  def __init__(\n","      self,\n","      in_channels,\n","      skip_channels,\n","      out_channels,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect',\n","      upsample_mode='transpose'):\n","    super(DecoderBlock, self).__init__()\n","\n","    self.skip_channels = skip_channels\n","    self.upsample_mode = upsample_mode\n","    \n","    # Upsampling\n","    if upsample_mode == 'transpose':\n","      self.deconv = nn.Sequential(\n","          nn.ConvTranspose2d(\n","              in_channels, out_channels,\n","              kernel_size=3, stride=2,\n","              padding=1, output_padding=1,\n","              bias=use_bias),\n","          norm_layer(out_channels),\n","          activation_func)\n","    else:\n","      self.deconv = UpConv2d(\n","          in_channels, out_channels,\n","          use_bias=use_bias,\n","          activation_func=activation_func,\n","          norm_layer=norm_layer,\n","          padding_type=padding_type,\n","          interpolate_mode=upsample_mode)\n","\n","    concat_channels = skip_channels + out_channels\n","    \n","    self.conv = Conv2d(\n","        concat_channels,\n","        out_channels,\n","        kernel_size=3,\n","        stride=1,\n","        activation_func=activation_func,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        use_bias=use_bias)\n","\n","  def forward(self, x, skip=None):\n","    deconv = self.deconv(x)\n","\n","    if self.skip_channels > 0:\n","      concat = torch.cat([deconv, skip], dim=1)\n","    else:\n","      concat = deconv\n","\n","    return self.conv(concat)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LibNgHWm4MIr"},"outputs":[],"source":["def init_weights(net, init_type='normal', init_gain=0.02):\n","  \"\"\"\n","  Initialize network weights.\n","  Parameters:\n","      net (network) -- network to be initialized\n","      init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n","      init_gain (float) -- scaling factor for normal, xavier and orthogonal.\n","  \"\"\"\n","  def init_func(m):  # define the initialization function\n","    classname = m.__class__.__name__\n","    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n","      if init_type == 'normal':\n","        init.normal_(m.weight.data, 0.0, init_gain)\n","      elif init_type == 'xavier':\n","        init.xavier_normal_(m.weight.data, gain=init_gain)\n","      elif init_type == 'kaiming':\n","        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","      elif init_type == 'orthogonal':\n","        init.orthogonal_(m.weight.data, gain=init_gain)\n","      else:\n","        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n","      if hasattr(m, 'bias') and m.bias is not None:\n","        init.constant_(m.bias.data, 0.0)\n","    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n","      init.normal_(m.weight.data, 1.0, init_gain)\n","      init.constant_(m.bias.data, 0.0)\n","\n","  print('initialize network with %s' % init_type)\n","  net.apply(init_func)  # apply the initialization function <init_func>\n","\n","def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n","  \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n","  Parameters:\n","          net (network) -- the network to be initialized\n","          init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n","          gain (float) -- scaling factor for normal, xavier and orthogonal.\n","          gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n","  Return an initialized network.\n","  \"\"\"\n","  if len(gpu_ids) > 0:\n","    assert(torch.cuda.is_available())\n","    net.to(gpu_ids[0])\n","    net = torch.nn.DataParallel(net, gpu_ids)    # multi-GPUs\n","  init_weights(net, init_type, init_gain=init_gain)\n","  \n","  # Zero for deform convs\n","  key_name_list = ['offset', 'modulator']\n","  for cur_name, parameters in net.named_parameters():\n","    if any(key_name in cur_name for key_name in key_name_list):\n","      nn.init.constant_(parameters, 0.)\n","  return net\n","\n","class ResNetModified(nn.Module):\n","  \"\"\"\n","  Resnet-based generator that consists of deformable Resnet blocks.\n","  \"\"\"\n","\n","  def __init__(\n","      self, \n","      input_nc, \n","      output_nc, \n","      ngf=64, \n","      norm_layer=nn.BatchNorm2d, \n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      use_dropout=False, \n","      n_blocks=6, \n","      padding_type='reflect',\n","      upsample_mode='bilinear'):\n","    \"\"\"Construct a Resnet-based generator\n","    Parameters:\n","      input_nc (int) -- the number of channels in input images\n","      output_nc (int) -- the number of channels in output images\n","      ngf (int) -- the number of filters in the last conv layer\n","      norm_layer -- normalization layer\n","      use_dropout (bool) -- if use dropout layers\n","      n_blocks (int) -- the number of ResNet blocks\n","      padding_type (str) -- the name of padding layer in conv layers: reflect | replicate | zero\n","      upsample_mode (str) -- mode for upsampling: transpose | bilinear\n","    \"\"\"\n","    assert(n_blocks >= 0)\n","    super(ResNetModified, self).__init__()\n","    if type(norm_layer) == functools.partial:\n","      use_bias = norm_layer.func == nn.InstanceNorm2d\n","    else:\n","      use_bias = norm_layer == nn.InstanceNorm2d\n","\n","    # Initial Convolution\n","    self.initial_conv = nn.Sequential(\n","        Conv2d(\n","            in_channels=input_nc,\n","            out_channels=ngf,\n","            kernel_size=7,\n","            padding_type=padding_type,\n","            norm_layer=norm_layer,\n","            activation_func=activation_func,\n","            use_bias=use_bias),\n","        Conv2d(\n","            in_channels=ngf,\n","            out_channels=ngf,\n","            kernel_size=3,\n","            padding_type=padding_type,\n","            norm_layer=norm_layer,\n","            activation_func=activation_func,\n","            use_bias=use_bias))\n","\n","    # Downsample Blocks\n","    n_downsampling = 2\n","    mult = 2 ** 0\n","    self.downsample_1 = Conv2d(\n","        in_channels=ngf * mult,\n","        out_channels=ngf * mult * 2,\n","        kernel_size=3,\n","        stride=2,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        activation_func=activation_func,\n","        use_bias=use_bias)\n","    \n","    mult = 2 ** 1\n","    self.downsample_2 = Conv2d(\n","        in_channels=ngf * mult,\n","        out_channels=ngf * mult * 2,\n","        kernel_size=3,\n","        stride=2,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        activation_func=activation_func,\n","        use_bias=use_bias)\n","\n","    # Residual Blocks\n","    residual_blocks = []\n","    mult = 2 ** n_downsampling\n","    for i in range(n_blocks): # add ResNet blocks\n","      residual_blocks += [\n","          DeformableResnetBlock(\n","              ngf * mult, \n","              padding_type=padding_type, \n","              norm_layer=norm_layer, \n","              use_dropout=use_dropout, \n","              use_bias=use_bias, activation_func=activation_func)]\n","    \n","    self.residual_blocks = nn.Sequential(*residual_blocks)\n","\n","    # Upsampling\n","    mult = 2 ** (n_downsampling - 0)\n","    self.upsample_2 = DecoderBlock(\n","        ngf * mult, \n","        int(ngf * mult / 2),\n","        int(ngf * mult / 2),\n","        use_bias=use_bias,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        padding_type=padding_type,\n","        upsample_mode=upsample_mode)\n","    \n","    mult = 2 ** (n_downsampling - 1)\n","    self.upsample_1 = DecoderBlock(\n","        ngf * mult, \n","        int(ngf * mult / 2),\n","        int(ngf * mult / 2),\n","        use_bias=use_bias,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        padding_type=padding_type,\n","        upsample_mode=upsample_mode)\n","    \n","    # Output Convolution\n","    self.output_conv_naive = nn.Sequential(\n","        nn.ReflectionPad2d(1),\n","        nn.Conv2d(ngf, output_nc, kernel_size=3, padding=0),\n","        nn.Tanh())\n","\n","    # # Projection for rain robust loss\n","    # self.feature_projection = nn.Sequential(\n","    #     nn.AdaptiveAvgPool2d((2, 2)),\n","    #     nn.Flatten(start_dim=1, end_dim=-1))\n","\n","  def forward(self, input):\n","    \"\"\"Standard forward\"\"\"\n","\n","    # Downsample\n","    initial_conv_out  = self.initial_conv(input)\n","    downsample_1_out = self.downsample_1(initial_conv_out)\n","    downsample_2_out = self.downsample_2(downsample_1_out)\n","\n","    # Residual\n","    residual_blocks_out = self.residual_blocks(downsample_2_out)\n","\n","    # Upsample\n","    upsample_2_out = self.upsample_2(residual_blocks_out, downsample_1_out)\n","    upsample_1_out = self.upsample_1(upsample_2_out, initial_conv_out)\n","    final_out = self.output_conv_naive(upsample_1_out)\n","\n","    # Features\n","    # features = self.feature_projection(residual_blocks_out)\n","\n","    # Return multiple final conv results\n","    return final_out, # features\n","\n","class GTRainModel(nn.Module):\n","  def __init__(\n","      self, \n","      ngf=64,\n","      n_blocks=9,\n","      norm_layer_type='batch',\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      upsample_mode='bilinear',\n","      init_type='kaiming'):\n","    \"\"\"\n","    GT-Rain Model\n","    Parameters:\n","      ngf (int) -- the number of conv filters\n","      n_blocks (int) -- the number of deformable ResNet blocks\n","      norm_layer_type (str) -- 'batch', 'instance'\n","      activation_func (func) -- activation functions\n","      upsample_mode (str) -- 'transpose', 'bilinear'\n","      init_type (str) -- None, 'normal', 'xavier', 'kaiming', 'orthogonal'\n","    \"\"\"\n","    super(GTRainModel, self).__init__()\n","    self.resnet = ResNetModified(\n","      input_nc=3, output_nc=3, ngf=ngf, \n","      norm_layer=get_norm_layer(norm_layer_type),\n","      activation_func=activation_func,\n","      use_dropout=False, n_blocks=n_blocks, \n","      padding_type='reflect',\n","      upsample_mode=upsample_mode)\n","\n","    # Initialization\n","    if init_type:\n","      init_net(self.resnet, init_type=init_type)\n","\n","  def forward(self, x):\n","    out_img = self.resnet(x)\n","    return out_img "]},{"cell_type":"markdown","metadata":{"id":"jht1wzqDDjJf"},"source":["# Parameters"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"NnJC-9nxpRlt"},"outputs":[],"source":["params = {\n","  'load_checkpoint': '/home/mdl/shared/afs6372/rain_challenge/GT-RAIN/model/model_checkpoint.pth', # Dir to load model weights\n","  'input_path': '/home/mdl/shared/afs6372/rain_challenge/data/GT-RAIN/GT-RAIN_val',\n","  'gt_path': '/home/mdl/shared/afs6372/rain_challenge/data/GT-RAIN/GT-RAIN_val',\n","  'save_path': '/home/mdl/shared/afs6372/rain_challenge/GT-RAIN/GTRM',\n","  'init_type': 'normal', # Initialization type \n","  'norm_layer_type': 'batch', # Normalization type\n","  'activation_func': torch.nn.LeakyReLU(negative_slope=0.10, inplace=True), # Activation function\n","  'upsample_mode': 'bilinear', # Mode for upsampling\n","  'ngf': 64,\n","  'n_blocks': 9}\n","\n","os.makedirs(params['save_path'], exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"m9jjxGsODD8F"},"source":["# Load Model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"za8W7tG_H3zZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["initialize network with normal\n","GTRainModel(\n","  (resnet): ResNetModified(\n","    (initial_conv): Sequential(\n","      (0): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((3, 3, 3, 3))\n","          (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (downsample_1): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (downsample_2): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (residual_blocks): Sequential(\n","      (0): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_2): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_1): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (output_conv_naive): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n","      (2): Tanh()\n","    )\n","  )\n",")\n"]},{"data":{"text/plain":["GTRainModel(\n","  (resnet): ResNetModified(\n","    (initial_conv): Sequential(\n","      (0): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((3, 3, 3, 3))\n","          (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (downsample_1): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (downsample_2): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (residual_blocks): Sequential(\n","      (0): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_2): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_1): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (output_conv_naive): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n","      (2): Tanh()\n","    )\n","  )\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Make the model\n","model = GTRainModel(\n","  ngf=params['ngf'],\n","  n_blocks=params['n_blocks'],\n","  norm_layer_type=params['norm_layer_type'],\n","  activation_func=params['activation_func'],\n","  upsample_mode=params['upsample_mode'],\n","  init_type=params['init_type'])\n","\n","print(model)\n","model.cuda()\n","#model = nn.DataParallel(model)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"t6IrOcuN8mrN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading weights: /home/mdl/shared/afs6372/rain_challenge/GT-RAIN/model/model_checkpoint.pth\n"]},{"data":{"text/plain":["GTRainModel(\n","  (resnet): ResNetModified(\n","    (initial_conv): Sequential(\n","      (0): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((3, 3, 3, 3))\n","          (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (downsample_1): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (downsample_2): Conv2d(\n","      (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","      (conv): Sequential(\n","        (0): ReflectionPad2d((1, 1, 1, 1))\n","        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (residual_blocks): Sequential(\n","      (0): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (8): DeformableResnetBlock(\n","        (conv_block): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (4): ReflectionPad2d((1, 1, 1, 1))\n","          (5): DeformableConv2d(\n","            (offset_conv): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1))\n","            (modulator_conv): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1))\n","            (regular_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          )\n","          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_2): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (upsample_1): DecoderBlock(\n","      (deconv): UpConv2d(\n","        (conv): Conv2d(\n","          (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","          (conv): Sequential(\n","            (0): ReflectionPad2d((1, 1, 1, 1))\n","            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (conv): Conv2d(\n","        (activation_func): LeakyReLU(negative_slope=0.1, inplace=True)\n","        (conv): Sequential(\n","          (0): ReflectionPad2d((1, 1, 1, 1))\n","          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (output_conv_naive): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n","      (2): Tanh()\n","    )\n","  )\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Load model weights\n","print('Loading weights:', params['load_checkpoint'])\n","checkpoint = torch.load(params['load_checkpoint']) #, map_location=torch.device('cpu')\n","model.load_state_dict(checkpoint['state_dict'], strict=True) #strict=True\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"IIP37_kzDHt2"},"source":["# Testing Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjiVjuLRpqI9"},"outputs":[],"source":["# Section for running with generic test sets\n","if params['gt_path']:\n","  total_PSNR_input = 0\n","  total_SSIM_input = 0\n","  total_PSNR_output = 0\n","  total_SSIM_output = 0\n","  clean_img_paths = natsorted(glob(params['gt_path']))\n","\n","rainy_img_paths = natsorted(glob(params['input_path']))\n","num_paths = len(rainy_img_paths)\n","\n","for i in tqdm(range(num_paths)):\n","  filename = rainy_img_paths[i].split('/')[-1][:-4]\n","  img = Image.open(rainy_img_paths[i])\n","  img = np.array(img, dtype=np.float32)\n","  img *= 1/255\n","  height, width = img.shape[:2]\n","\n","  img = img[:height-height%4,:width-width%4,:]\n","  input = torch.from_numpy(img).permute((2, 0, 1)) * 2 - 1\n","  input = torch.unsqueeze(input, 0).cuda()\n","  output = (model(input)[0]* 0.5 + 0.5).squeeze().permute((1, 2, 0))\n","  output = output.detach().cpu().numpy()\n","\n","  if params['gt_path']:\n","    gt_img = Image.open(clean_img_paths[i])\n","    gt_img = np.array(gt_img, dtype=np.float32)\n","    gt_img *= 1/255\n","    gt_img = gt_img[:height-height%4,:width-width%4,:]  \n","    total_PSNR_input += psnr(gt_img, img)\n","    total_SSIM_input += ssim(gt_img, img, multichannel=True)\n","    total_PSNR_output += psnr(gt_img, output)\n","    total_SSIM_output += ssim(gt_img, output, multichannel=True)\n","\n","  # USE THIS BLOCK TO SAVE\n","  im = Image.fromarray((output*255).astype(np.uint8))\n","  im.save(f\"{params['save_path']}/{filename}.png\")\n","\n","if params['gt_path']:\n","  print(f\"PSNR Input: {total_PSNR_input/num_paths}\")\n","  print(f\"SSIM Input: {total_SSIM_input/num_paths}\")\n","  print(f\"PSNR Output: {total_PSNR_output/num_paths}\")\n","  print(f\"SSIM Output: {total_SSIM_output/num_paths}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"bol1boaGy7L1"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c22e53e5d7cd453c8679f02c78e3d3df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b516d24f56104dd4b10bf21b702ba145","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/293 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Alpine_WY_0-0\n","Scene PSNR Input: 21.387388921552674\n","Scene SSIM Input: 0.7397515252995409\n","Scene PSNR Output: 18.680111128465494\n","Scene SSIM Output: 0.6839879749171156\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b059d6dbfdb42638f3527f8374ed4e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Auron_Ski_0-0\n","Scene PSNR Input: 15.938161747981885\n","Scene SSIM Input: 0.7750771137078604\n","Scene PSNR Output: 23.2123985011598\n","Scene SSIM Output: 0.7915984928607941\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97c820ef93ba4d11a50eb8cb3b08502f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Chuo_0-0\n","Scene PSNR Input: 16.40974517538182\n","Scene SSIM Input: 0.6026424396038056\n","Scene PSNR Output: 16.153749886444615\n","Scene SSIM Output: 0.6365190974871318\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f76215cf86d540158f0a45e4ef8c90ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Gurutto_1-2\n","Scene PSNR Input: 22.665552398863646\n","Scene SSIM Input: 0.6213237051169077\n","Scene PSNR Output: 23.519165433931025\n","Scene SSIM Output: 0.6608614180485407\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"156e08a9df2f4bd0b6a800491c192ab2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Oinari_0-1\n","Scene PSNR Input: 20.042827867046416\n","Scene SSIM Input: 0.7005772387981415\n","Scene PSNR Output: 19.549130880287613\n","Scene SSIM Output: 0.6658620808521907\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f029ab0d09a24bd69155f572a4d3c0f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Oinari_1-0\n","Scene PSNR Input: 16.753487492055584\n","Scene SSIM Input: 0.6044744954506556\n","Scene PSNR Output: 17.473689053770116\n","Scene SSIM Output: 0.6293680963913599\n","Total PSNR Input: 18.86619393381367\n","Total SSIM Input: 0.6739744196628186\n","Total PSNR Output: 19.764707480676442\n","Total SSIM Output: 0.6780328600928556\n"]},{"ename":"ZeroDivisionError","evalue":"division by zero","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal PSNR Output: \u001b[39m\u001b[39m{\u001b[39;00mtotal_PSNR_output\u001b[39m/\u001b[39mnum_scenes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal SSIM Output: \u001b[39m\u001b[39m{\u001b[39;00mtotal_SSIM_output\u001b[39m/\u001b[39mnum_scenes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrain accumulation Total PSNR Input: \u001b[39m\u001b[39m{\u001b[39;00mrain_acc_total_PSNR_input\u001b[39m/\u001b[39m(rain_acc_num_scenes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrain accumulation Total SSIM Input: \u001b[39m\u001b[39m{\u001b[39;00mrain_acc_total_SSIM_input\u001b[39m/\u001b[39mrain_acc_num_scenes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrain accumulation Total PSNR Output: \u001b[39m\u001b[39m{\u001b[39;00mrain_acc_total_PSNR_output\u001b[39m/\u001b[39mrain_acc_num_scenes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}],"source":["# Section for running on GT-RAIN test set\n","total_PSNR_input = 0\n","total_SSIM_input = 0\n","total_PSNR_output = 0\n","total_SSIM_output = 0\n","\n","rain_acc_total_PSNR_input = 0\n","rain_acc_total_SSIM_input = 0\n","rain_acc_total_PSNR_output = 0\n","rain_acc_total_SSIM_output = 0\n","rain_acc_num_scenes = 0\n","\n","dense_streak_total_PSNR_input = 0\n","dense_streak_total_SSIM_input = 0\n","dense_streak_total_PSNR_output = 0\n","dense_streak_total_SSIM_output = 0\n","dense_streak_num_scenes = 0\n","\n","scene_paths = natsorted(glob(f\"{params['input_path']}/*\"))\n","\n","for scene_path in tqdm(scene_paths):\n","  scene_name = scene_path.split('/')[-1]\n","  clean_img_path = glob(scene_path + '/*C-000.png')[0]\n","  rainy_img_paths = natsorted(glob(scene_path + '/*R-*.png'))\n","  scene_PSNR_input = 0\n","  scene_SSIM_input = 0\n","  scene_PSNR_output = 0\n","  scene_SSIM_output = 0\n","  \n","  for i in tqdm(range(len(rainy_img_paths))):\n","    filename = rainy_img_paths[i].split('/')[-1][:-4]\n","    img = Image.open(rainy_img_paths[i])\n","    gt_img = Image.open(clean_img_path)\n","    img = np.array(img, dtype=np.float32)\n","    img *= 1/255\n","    gt_img = np.array(gt_img, dtype=np.float32)\n","    gt_img *= 1/255\n","    height, width = img.shape[:2]\n","\n","    img = img[:height-height%4,:width-width%4,:]\n","    \n","    gt_img = gt_img[:height-height%4,:width-width%4,:]\n","    \n","    input = torch.from_numpy(img).permute((2, 0, 1)) * 2 - 1\n","    input = torch.unsqueeze(input, 0).cuda()\n","    output = (model(input)[0]* 0.5 + 0.5).squeeze().permute((1, 2, 0))\n","    output = output.detach().cpu().numpy()\n","\n","    # USE THIS BLOCK TO SAVE\n","    im = Image.fromarray((output*255).astype(np.uint8))\n","    os.makedirs(f\"{params['save_path']}/{scene_name}\", exist_ok=True)\n","    im.save(f\"{params['save_path']}/{scene_name}/{filename}.png\")\n","\n","    scene_PSNR_input += psnr(gt_img, img)\n","    scene_SSIM_input += ssim(gt_img, img, multichannel=True, win_size=11, data_range=1.0, channel_axis=2) \n","    scene_PSNR_output += psnr(gt_img, output)\n","    scene_SSIM_output += ssim(gt_img, output, multichannel=True, win_size=11, data_range=1.0, channel_axis=2)\n","  print(f\"Scene: {scene_name}\")\n","  print(f\"Scene PSNR Input: {scene_PSNR_input/len(rainy_img_paths)}\")\n","  print(f\"Scene SSIM Input: {scene_SSIM_input/len(rainy_img_paths)}\")\n","  print(f\"Scene PSNR Output: {scene_PSNR_output/len(rainy_img_paths)}\")\n","  print(f\"Scene SSIM Output: {scene_SSIM_output/len(rainy_img_paths)}\")\n","\n","  total_PSNR_input += scene_PSNR_input/len(rainy_img_paths)\n","  total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","  total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","  total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","\n","  if scene_name in [\"Oinari_0-0\", \"M1135_0-0\", \"Table_Rock_0-0\"]:\n","    rain_acc_total_PSNR_input += scene_PSNR_input/len(rainy_img_paths) \n","    rain_acc_total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","    rain_acc_total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","    rain_acc_total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","    rain_acc_num_scenes+=1\n","  else:\n","    dense_streak_total_PSNR_input+= scene_PSNR_input/len(rainy_img_paths)\n","    dense_streak_total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","    dense_streak_total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","    dense_streak_total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","    dense_streak_num_scenes+=1\n","num_scenes = len(scene_paths)\n","print(f\"Total PSNR Input: {total_PSNR_input/(num_scenes)}\")\n","print(f\"Total SSIM Input: {total_SSIM_input/num_scenes}\")\n","print(f\"Total PSNR Output: {total_PSNR_output/num_scenes}\")\n","print(f\"Total SSIM Output: {total_SSIM_output/num_scenes}\")\n","\n","print(f\"rain accumulation Total PSNR Input: {rain_acc_total_PSNR_input/(rain_acc_num_scenes)}\")\n","print(f\"rain accumulation Total SSIM Input: {rain_acc_total_SSIM_input/rain_acc_num_scenes}\")\n","print(f\"rain accumulation Total PSNR Output: {rain_acc_total_PSNR_output/rain_acc_num_scenes}\")\n","print(f\"rain accumulation Total SSIM Output: {rain_acc_total_SSIM_output/rain_acc_num_scenes}\")\n","\n","print(f\"dense streak Total PSNR Input: {dense_streak_total_PSNR_input/(dense_streak_num_scenes)}\")\n","print(f\"dense streak Total SSIM Input: {dense_streak_total_SSIM_input/dense_streak_num_scenes}\")\n","print(f\"dense streak Total PSNR Output: {dense_streak_total_PSNR_output/dense_streak_num_scenes}\")\n","print(f\"dense streak Total SSIM Output: {dense_streak_total_SSIM_output/dense_streak_num_scenes}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Ensembling"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["from collections import OrderedDict\n","ensemble_paths = OrderedDict()\n","ensemble_paths[\"Validaton\"] = \"/home/mdl/shared/afs6372/rain_challenge/data/GT-RAIN/GT-RAIN_val\"\n","ensemble_paths[\"Restormer\"] = \"/home/mdl/shared/afs6372/rain_challenge/data/GT-RAIN/GT-RAIN_val_restormer\"\n","ensemble_paths[\"Restormer_GTRM\"] = \"/home/mdl/shared/afs6372/rain_challenge/GT-RAIN/Restormer_GTRM\"\n","ensemble_paths[\"GTRM\"] = \"/home/mdl/shared/afs6372/rain_challenge/GT-RAIN/GTRM\"\n","\n","ensemble_weights = OrderedDict()\n","ensemble_weights[\"Validaton\"] =  0.1 #0.1\n","ensemble_weights[\"Restormer\"] = 0.8\n","ensemble_weights[\"Restormer_GTRM\"] = 0.05#  0.05\n","ensemble_weights[\"GTRM\"] =  0.05#0.05\n","\n","ensemble_metrics = {\n","}"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["def get_ensemble_image(foldername, filename):\n","    img = None\n","    gt_size = None\n","    for (model_name, model_image_paths) in ensemble_paths.items():\n","        path = os.path.join(model_image_paths, foldername, filename)\n","        # print(f\"{model_name} : {path}\")\n","        im = Image.open(path)\n","\n","        # keep track of image size \n","        if gt_size is None: \n","            gt_size = im.size\n","\n","        # resize if not the same size \n","        if gt_size != im.size:\n","            im = im.resize(gt_size)\n","\n","        # print(f\"{model_name}, {im.size}\")\n","        im = np.array(im, dtype=np.float32)\n","        \n","        if img is None:\n","            img = ensemble_weights[model_name]*im\n","        else:\n","            img += ensemble_weights[model_name]*im\n","    return img "]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07f847c55050461b8c7f28eb57c42dc8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"232788aa4aea4859921bf7f47c192265","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/293 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Alpine_WY_0-0\n","Scene PSNR Output: 21.1064277945125\n","Scene SSIM Output: 0.7445533715010503\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a5e1f50508a476fa8725cc764129b39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Auron_Ski_0-0\n","Scene PSNR Output: 24.541766143445948\n","Scene SSIM Output: 0.7951153165102005\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ca6b8059cac49d4b96a05e159161bbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Chuo_0-0\n","Scene PSNR Output: 16.10309824414151\n","Scene SSIM Output: 0.6261595877011618\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3cdaac0ce0b4842b1108008ac1ad7c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Gurutto_1-2\n","Scene PSNR Output: 24.195416797982023\n","Scene SSIM Output: 0.6753722502787908\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39b5606bc8cf4a93a5c62be8bef5160e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Oinari_0-1\n","Scene PSNR Output: 19.898012488348545\n","Scene SSIM Output: 0.6682029662529627\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0abd3593021046998c92cb137674c8b3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Scene: Oinari_1-0\n","Scene PSNR Output: 18.031246092692697\n","Scene SSIM Output: 0.6160119893153508\n","Total PSNR Output: 20.645994593520538\n","Total SSIM Output: 0.6875692469265862\n"]}],"source":["# Section for running on GT-RAIN test set\n","total_PSNR_output = 0\n","total_SSIM_output = 0\n","\n","scene_paths = natsorted(glob(f\"{params['input_path']}/*\"))\n","\n","for scene_path in tqdm(scene_paths):\n","  \n","  scene_name = scene_path.split('/')[-1]\n","  clean_img_path = glob(scene_path + '/*C-000.png')[0]\n","  rainy_img_paths = natsorted(glob(scene_path + '/*R-*.png'))\n","\n","  scene_PSNR_output = 0\n","  scene_SSIM_output = 0\n","  \n","  for i in tqdm(range(len(rainy_img_paths))):\n","    filename = rainy_img_paths[i].split('/')[-1]\n","    foldername = rainy_img_paths[i].split('/')[-2]\n","\n","    # get weighted output \n","    img = get_ensemble_image(foldername, filename)\n","    img *= 1/255\n","    gt_img = Image.open(clean_img_path)\n","    gt_img = np.array(gt_img, dtype=np.float32)\n","    gt_img *= 1/255 \n","\n","    # USE THIS BLOCK TO SAVE\n","    # im = Image.fromarray((output*255).astype(np.uint8))\n","    # os.makedirs(f\"{params['save_path']}/{scene_name}\", exist_ok=True)\n","    # im.save(f\"{params['save_path']}/{scene_name}/{filename}.png\")\n","\n","    scene_PSNR_output += psnr(gt_img, img)\n","    scene_SSIM_output += ssim(gt_img, img, multichannel=True, win_size=11, data_range=1.0, channel_axis=2)\n","    \n","  print(f\"Scene: {scene_name}\")\n","  print(f\"Scene PSNR Output: {scene_PSNR_output/len(rainy_img_paths)}\")\n","  print(f\"Scene SSIM Output: {scene_SSIM_output/len(rainy_img_paths)}\")\n","\n","\n","  total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","  total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","\n","\n","num_scenes = len(scene_paths)\n","print(f\"Total PSNR Output: {total_PSNR_output/num_scenes}\")\n","print(f\"Total SSIM Output: {total_SSIM_output/num_scenes}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Restormer alone: \n","\n","Total PSNR Output: 20.72991493703425 </br>\n","Total SSIM Output: 0.6839475443956976"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"DiT","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"vscode":{"interpreter":{"hash":"e0819536ab917d319fc41cbb092dcf9b232cf60355042c4ca1fd03bccba47af1"}}},"nbformat":4,"nbformat_minor":0}
